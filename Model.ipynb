{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom pickle import load\nimport pickle\n\n\nimport copy\nimport tensorflow as tf\n\npath_stories = '../input/text-sum-load-and-preprocess-dataset/cnn_dataset.pkl'\nnp.random.seed(9001)\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['glove840b300dtxt', 'glove6b100dtxt', 'russian-glove', 'text-sum-load-and-preprocess-dataset']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "stories = load(open(path_stories, 'rb'))\nprint('Loaded Stories %d' % len(stories))",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Loaded Stories 92579\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1356c65d8b1a67e26e3563805b41f451d475a67c"
      },
      "cell_type": "code",
      "source": "print(stories[0])",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'story': ['london england reuters harry potter star daniel radcliffe gain access to a reported million million fortune a he turn on monday but he insists the money wont cast a spell on him', 'daniel radcliffe a harry potter in harry potter and the order of the phoenix', 'to the disappointment of gossip columnist around the world the young actor say he ha no plan to fritter his cash away on fast car drink and celebrity party', 'i dont plan to be one of those people who a soon a they turn suddenly buy themselves a massive sport car collection or something similar he told an australian interviewer earlier this month i dont think ill be particularly extravagant', 'the thing i like buying are thing that cost about pound book and cd and dvd', 'at radcliffe will be able to gamble in a casino buy a drink in a pub or see the horror film hostel part ii currently six place below his number one movie on the uk box office chart', 'detail of how hell mark his landmark birthday are under wrap his agent and publicist had no comment on his plan', 'ill definitely have some sort of party he said in an interview hopefully none of you will be reading about it', 'radcliffes earnings from the first five potter film have been held in a trust fund which he ha not been able to touch', 'despite his growing fame and rich the actor say he is keeping his foot firmly on the ground', 'people are always looking to say kid star go off the rail he told reporter last month but i try very hard not to go that way because it would be too easy for them', 'his latest outing a the boy wizard in harry potter and the order of the phoenix is breaking record on both side of the atlantic and he will reprise the role in the last two film watch ireporter give her review of potter latest', 'there is life beyond potter however', 'the londoner ha filmed a tv movie called my boy jack about author rudyard kipling and his son due for release later this year he will also appear in december boy an australian film about four boy who escape an orphanage', 'earlier this year he made his stage debut playing a tortured teenager in peter shaffers equus', 'meanwhile he is braced for even closer medium scrutiny now that he legally an adult i just think im going to be more sort of fair game he told reuters email to a friend', 'copyright reuters all right reservedthis material may not be published broadcast rewritten or redistributed'], 'highlights': ['harry potter star daniel radcliffe get fortune a he turn monday', 'young actor say he ha no plan to fritter his cash away', 'radcliffes earnings from first five potter film have been held in trust fund']}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de5209107cd39d94e294e360b27df665e3bc838f"
      },
      "cell_type": "code",
      "source": "def load_data(path):\n    stories = load(open(path, 'rb'))\n    text_sentences = ''\n    summary_sentences = ''\n    stories = stories[:1500]\n    for i in range(len(stories)):\n        text_sentences += ' '.join(stories[i]['story'])\n        summary_sentences += ' '.join(stories[i]['highlights'])\n        if i != len(stories)-1:\n            text_sentences += '\\n'\n            summary_sentences += '\\n'\n    return text_sentences, summary_sentences",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32d5f399325c1714c32df1591c9931a2a4551da5"
      },
      "cell_type": "code",
      "source": "np.random.seed(9001)\nEMBEDDING_DIMENSION = 100 # Available dimensions for 6B data is 50, 100, 200, 300\n\nglove_weights_file_path = '../input/glove6b100dtxt/glove.6B.100d.txt'\n\nCODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n\n# считывать файл ембедингов создавать три переменные и возвращать\ndef create_lookup_tables():\n    \n    weights = list()\n    # starts with the special tokens\n    word_to_id = copy.copy(CODES)\n    \n    with open(glove_weights_file_path, 'r') as file: \n        for index, line in enumerate(file): \n            values = line.split() # word and weights separated by space\n            word = values[0] # word is first symbol on each line\n            word_weights = np.asarray(values[1:], dtype=np.float32) # remainder of line is weights for word\n            # PAD, EOS, UNK, GO is our zeroth, first, second, third indices so shift by four\n            word_to_id[word] = index + 4 \n            weights.append(word_weights)\n            \n    # insert the PAD, EOS, UNK, GO weights at indices 0, 1, 2, 3 respectively \n    weights.insert(0, np.random.randn(EMBEDDING_DIMENSION)) \n    weights.insert(1, np.random.randn(EMBEDDING_DIMENSION))\n    weights.insert(2, np.random.randn(EMBEDDING_DIMENSION)) \n    weights.insert(3, np.random.randn(EMBEDDING_DIMENSION)) \n    \n    weights = np.asarray(weights, dtype=np.float32)\n    id_to_word = {v_i: v for v, v_i in word_to_id.items()}\n    \n    \n    return word_to_id, id_to_word, weights",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7cee6f8911cae850fb9588e8d9088c1858a50d0"
      },
      "cell_type": "code",
      "source": "# word_to_id в оба параметра\ndef text_to_ids(source_text, target_text, word_to_id):\n    \"\"\"\n        1st, 2nd args: raw string text to be converted\n        3rd, 4th args: lookup tables for 1st and 2nd args respectively\n    \n        return: A tuple of lists (source_id_text, target_id_text) converted\n    \"\"\"\n    # empty list of converted sentences\n    source_text_id = []\n    target_text_id = []\n    \n    # make a list of sentences (extraction)\n    source_sentences = source_text.split(\"\\n\")\n    target_sentences = target_text.split(\"\\n\")\n    \n    # iterating through each sentences (# of sentences in source&target is the same)\n    for i in range(len(source_sentences)):\n        # extract sentences one by one\n        source_sentence = source_sentences[i]\n        target_sentence = target_sentences[i]\n        # make a list of tokens/words (extraction) from the chosen sentence\n        source_tokens = source_sentence.split(\" \")\n        target_tokens = target_sentence.split(\" \")\n        \n        # empty list of converted words to index in the chosen sentence\n        source_token_id = []\n        target_token_id = []\n        # вместо word to idx\n        for index, token in enumerate(source_tokens):\n            if (token != \"\"):\n                source_token_id.append(word_to_id.get(token, word_to_id['<UNK>']))\n        \n        for index, token in enumerate(target_tokens):\n            if (token != \"\"):\n                target_token_id.append(word_to_id.get(token, word_to_id['<UNK>']))\n                \n        # put <EOS> token at the end of the chosen target sentence\n        # this token suggests when to stop creating a sequence\n        target_token_id.append(word_to_id['<EOS>'])\n            \n        # add each converted sentences in the final list\n        source_text_id.append(source_token_id)\n        target_text_id.append(target_token_id)\n    \n    return source_text_id, target_text_id",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8df20c56328c49f4c247f2e7df0fb23e3ab8e659"
      },
      "cell_type": "code",
      "source": "def preprocess_and_save_data(path):\n    # Preprocess\n    \n    # load original data (text, summary)\n    source_text_words, target_text_words = load_data(path)\n    word_to_id, id_to_word, glove_weights = create_lookup_tables()\n    \n    # create list of sentences whose words are represented in index\n    source_text_int, target_text_int = text_to_ids(source_text_words, target_text_words, word_to_id)\n\n    # Save data for later use\n    pickle.dump((\n        (source_text_int, target_text_int),\n        word_to_id,\n        id_to_word,\n        glove_weights), open('preprocess.p', 'wb'))",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b11bc5bb2c5acf4f0b5d018c4c67bc11c411a6fa"
      },
      "cell_type": "code",
      "source": "preprocess_and_save_data(path_stories)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b33f85eba6047bab62510ce3e11d78feeaa86934"
      },
      "cell_type": "code",
      "source": "def load_preprocess():\n    with open('preprocess.p', mode='rb') as in_file:\n        return pickle.load(in_file)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f7c95954acdfc12e1e692f24e81ca7e910e281b"
      },
      "cell_type": "code",
      "source": "(source_int_text, target_int_text), word_to_id, id_to_word, glove_weights = load_preprocess()",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e63d8d2a5062d7c74acdecfc67ac53e29a68e14"
      },
      "cell_type": "code",
      "source": "# testing preprocessing\nprint(source_int_text[0])\nprint(target_int_text[0])\nfor k, v in word_to_id.items():\n    print(k, v)\n    if v == 10:\n        break",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[520, 567, 10855, 3219, 7658, 757, 2592, 20053, 1889, 1126, 8, 11, 297, 97, 97, 5175, 11, 22, 894, 17, 187, 38, 22, 4975, 4, 312, 58548, 1788, 11, 6256, 17, 107, 2592, 20053, 11, 3219, 7658, 10, 3219, 7658, 9, 4, 464, 7, 4, 3612, 8, 4, 6716, 7, 13374, 5739, 208, 4, 89, 4, 465, 2022, 207, 22, 8361, 88, 398, 8, 102694, 30, 1488, 424, 17, 1609, 573, 4607, 9, 5174, 169, 45, 46772, 398, 8, 34, 52, 7, 159, 73, 42, 11, 724, 11, 43, 894, 3713, 991, 1004, 11, 1975, 1939, 573, 1724, 50, 649, 797, 22, 158, 33, 807, 19605, 354, 41, 233, 45, 46772, 273, 3122, 34, 1117, 20227, 4, 877, 45, 121, 2197, 36, 877, 16, 776, 63, 3609, 543, 9, 3541, 9, 4184, 26, 20053, 47, 34, 671, 8, 9446, 10, 11, 5395, 991, 11, 4607, 10, 11, 10453, 50, 257, 4, 5992, 323, 20737, 157, 823, 843, 232, 245, 1272, 30, 227, 52, 1009, 17, 4, 2050, 1934, 287, 3103, 4606, 7, 201, 5617, 803, 30, 4820, 4162, 36, 128, 9011, 30, 1971, 9, 15821, 44, 88, 1324, 17, 30, 398, 3122, 3940, 37, 81, 2602, 7, 169, 22, 20, 10, 33, 966, 6203, 2129, 7, 85, 47, 34, 2189, 63, 24, 2, 1466, 29, 4, 62, 178, 7658, 323, 37, 55, 261, 10, 11, 1857, 876, 46, 22, 8361, 40, 55, 671, 8, 3259, 508, 30, 992, 3156, 9, 1731, 4, 2022, 207, 22, 18, 2279, 30, 2153, 6513, 17, 4, 821, 73, 36, 694, 866, 8, 207, 4317, 757, 246, 142, 4, 3091, 22, 158, 3042, 80, 233, 38, 45, 845, 195, 609, 40, 8, 246, 16, 183, 117, 24, 58, 34, 321, 1677, 14, 105, 30, 997, 12738, 11, 4, 1610, 13164, 10, 3219, 7658, 9, 4, 464, 7, 4, 3612, 18, 2927, 388, 17, 154, 441, 7, 4, 2357, 9, 22, 47, 22931, 4, 546, 10, 4, 80, 59, 323, 1720, 2, 459, 75, 1291, 7, 7658, 997, 67, 18, 218, 1519, 7658, 216, 4, 58205, 8361, 6228, 11, 820, 1009, 179, 196, 1610, 2184, 63, 1719, 53328, 37607, 9, 30, 634, 449, 14, 717, 172, 41, 66, 22, 47, 56, 1654, 10, 474, 1610, 33, 807, 323, 63, 137, 1610, 42, 2972, 33, 16280, 354, 41, 66, 22, 120, 30, 916, 1608, 701, 11, 8336, 7190, 10, 1298, 2, 73140, 1053, 22, 18, 20463, 14, 155, 2390, 3189, 6794, 118, 16, 22, 5758, 33, 3318, 45, 124, 273, 14667, 226, 8, 34, 60, 2602, 7, 1795, 190, 22, 158, 10855, 12247, 8, 11, 1413, 4790, 10855, 68, 252, 2, 1308, 111, 40, 34, 739, 1922, 25491, 50, 40812]\n[3219, 7658, 757, 2592, 20053, 173, 5175, 11, 22, 894, 187, 465, 2022, 207, 22, 8361, 88, 398, 8, 102694, 30, 1488, 424, 2, 1466, 29, 62, 178, 7658, 323, 37, 55, 261, 10, 1857, 876, 1]\n<PAD> 0\n<EOS> 1\n<UNK> 2\n<GO> 3\nthe 4\n, 5\n. 6\nof 7\nto 8\nand 9\nin 10\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fda822861b635cbe0ec9d936c6df76f44ec75a82"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e65d2937cca1a6bf5956ddf169b59ddae56667d"
      },
      "cell_type": "code",
      "source": "def enc_dec_model_inputs():\n    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n    targets = tf.placeholder(tf.int32, [None, None], name='targets') \n    \n    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n    max_target_len = tf.reduce_max(target_sequence_length)    \n    \n    return inputs, targets, target_sequence_length, max_target_len",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b6d50c6fa52b0ae0716660e66c5c845bd605352"
      },
      "cell_type": "code",
      "source": "def hyperparam_inputs():\n    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n    \n    return lr_rate, keep_prob",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a9303f0924019d9e6167ee4a82c045c86f7d1d1"
      },
      "cell_type": "code",
      "source": "# check\ndef process_decoder_input(target_data, word_to_id, batch_size):\n    \"\"\"\n    Preprocess target data for encoding\n    :return: Preprocessed target data\n    \"\"\"\n    # get '<GO>' id\n    \n    # may be it should be one-hot vector\n    go_id = word_to_id['<GO>']\n    \n    after_slice = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n    \n    return after_concat",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb03452c746bd243385d089826aec6097c529471"
      },
      "cell_type": "code",
      "source": "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n                   encoding_embedding_size, embedding_weights):\n    \"\"\"\n    :return: tuple (RNN output, RNN state)\n    \"\"\"\n    # get glove representation of words from rnn_inputs\n    embed = tf.nn.embedding_lookup(embedding_weights, rnn_inputs)\n    \n    stacked_cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(rnn_size), keep_prob) for _ in range(num_layers)])\n    \n    #try to set sequence_length param to sentane length\n    # as time_major == False, inputs must be a Tensor of shape: [batch_size, max_time, ...]\n    \n    # try to change to tf.nn.bidirectional_dynamic_rnn\n    outputs, state = tf.nn.dynamic_rnn(stacked_cells, \n                                       embed, \n                                       dtype=tf.float32)\n    \n    return outputs, state",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9607aab73510631b62f9201fff26cf53c9b2c7a"
      },
      "cell_type": "code",
      "source": "def decoding_layer_train(enc_outputs, encoder_state, rnn_size, dec_cell, dec_embed_input, \n                         target_sequence_length, max_summary_length, \n                         output_layer, keep_prob):\n    \"\"\"\n    Create a training process in decoding layer \n    :return: BasicDecoderOutput containing training logits and sample_id\n    \"\"\"\n    \n    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n                                             output_keep_prob=keep_prob)\n    ## Attention layer\n    # chenge\n    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n            num_units = rnn_size, # depth of query mechanism\n            memory = enc_outputs, # hidden states to attend (output of RNN)\n            normalize=True, # normalize energy term\n            name='BahdanauAttention')\n    \n    attention_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, \n                                                         attention_mechanism)\n    \n    decoder_initial_state = attention_cell.zero_state(batch_size, tf.float32).clone(\n          cell_state=encoder_state)\n    \n    # for only input layer\n    helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, \n                                               target_sequence_length)\n    \n    decoder = tf.contrib.seq2seq.BasicDecoder(attention_cell, \n                                              helper, \n                                              decoder_initial_state, \n                                              output_layer)\n\n    # unrolling the decoder layer\n    # returns final_outputs, final_state, final_sequence_lengths\n    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n                                                      impute_finished=True, \n                                                      maximum_iterations=max_summary_length)\n    return outputs",
      "execution_count": 69,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85e27424ff965783f93da791b6a5b831b75c45c7"
      },
      "cell_type": "code",
      "source": "def decoding_layer_infer(enc_outputs, encoder_state, rnn_size, dec_cell, \n                         embedding_weights, start_of_sequence_id,\n                         end_of_sequence_id, max_target_sequence_length,\n                         output_layer, batch_size, keep_prob, beam_width):\n    \"\"\"\n    Create a inference process in decoding layer \n    :return: BasicDecoderOutput containing inference logits and sample_id\n    \"\"\"\n    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n                                             output_keep_prob=keep_prob)\n    \n    tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(enc_outputs, \n                                                          multiplier=beam_width)\n    \n    tiled_encoder_final_state = tf.contrib.seq2seq.tile_batch(encoder_state, \n                                                             multiplier=beam_width)\n    \n    \n    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n            num_units = rnn_size, # depth of query mechanism\n            memory = tiled_encoder_outputs, # hidden states to attend (output of RNN)\n            normalize=True, # normalize energy term\n            name='BahdanauAttention')\n    \n    attention_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, \n                                                         attention_mechanism, \n                                                         attention_layer_size=rnn_size)\n    \n    decoder_initial_state = attention_cell.zero_state(dtype=tf.float32, \n                                                      batch_size=batch_size * beam_width)\n    \n    decoder_initial_state = decoder_initial_state.clone(cell_state=tiled_encoder_final_state)\n    \n    decoder = tf.contrib.seq2seq.BeamSearchDecoder(cell=attention_cell,\n                                                   embedding=embedding_weights,\n                                                   start_tokens=tf.fill([batch_size], start_of_sequence_id), \n                                                   end_token=end_of_sequence_id,\n                                                   initial_state=decoder_initial_state,\n                                                   beam_width=beam_width,\n                                                   output_layer=output_layer,\n                                                   length_penalty_weight=0.0)\n    \n    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, \n                                                      impute_finished=True, \n                                                      maximum_iterations=max_target_sequence_length)\n    return outputs",
      "execution_count": 70,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a24a34cdd73cafa603d3e8eb55b2b05865be993"
      },
      "cell_type": "code",
      "source": "def decoding_layer(dec_input, enc_outputs, encoder_state, target_sequence_length,\n                   max_target_sequence_length, vocab_size, rnn_size,num_layers,\n                   word_to_id, batch_size, keep_prob, decoding_embedding_size,\n                   beam_width, embedding_weights):\n    \"\"\"\n    Create decoding layer\n    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n    \"\"\"\n    \n    dec_embed_input = tf.nn.embedding_lookup(embedding_weights, dec_input)\n    cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(rnn_size) for _ in range(num_layers)])\n    \n    with tf.variable_scope(\"decode\"):\n        output_layer = tf.layers.Dense(vocab_size)\n        train_output = decoding_layer_train(enc_outputs,\n                                            encoder_state,\n                                            rnn_size,\n                                            cells,\n                                            dec_embed_input, \n                                            target_sequence_length, \n                                            max_target_sequence_length, \n                                            output_layer, \n                                            keep_prob)\n        \n    with tf.variable_scope(\"decode\", reuse=True):\n        infer_output = decoding_layer_infer(enc_outputs,\n                                            encoder_state,\n                                            rnn_size,\n                                            cells, \n                                            embedding_weights, \n                                            word_to_id['<GO>'], \n                                            word_to_id['<EOS>'], \n                                            max_target_sequence_length, \n                                            output_layer,\n                                            batch_size,\n                                            keep_prob,\n                                            beam_width)\n\n    return (train_output, infer_output)",
      "execution_count": 71,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8879fb2247a8b625571009a1b6926cc2936ec836"
      },
      "cell_type": "code",
      "source": "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n                  target_sequence_length, max_target_sentence_length,\n                  vocab_size, enc_embedding_size, dec_embedding_size,\n                  rnn_size, num_layers, word_to_id, beam_width, weights):\n    \"\"\"\n    Build the Sequence-to-Sequence model\n    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n    \"\"\"\n    \n    glove_weights_initializer = tf.constant_initializer(weights)\n    embedding_weights = tf.get_variable(name='embedding_weights', \n                                        shape=(weights.shape[0], \n                                        encoding_embedding_size), \n                                        initializer=glove_weights_initializer,\n                                        trainable=False)\n    \n    enc_outputs, enc_states = encoding_layer(input_data, \n                                             rnn_size, \n                                             num_layers, \n                                             keep_prob, \n                                             enc_embedding_size, \n                                             embedding_weights)\n    \n    dec_input = process_decoder_input(target_data, \n                                      word_to_id, \n                                      batch_size)\n    \n    train_output, infer_output = decoding_layer(dec_input,\n                                                enc_outputs,\n                                                enc_states, \n                                                target_sequence_length, \n                                                max_target_sentence_length,\n                                                vocab_size,\n                                                rnn_size,\n                                                num_layers,\n                                                word_to_id,\n                                                batch_size,\n                                                keep_prob,\n                                                dec_embedding_size, \n                                                beam_width,\n                                                embedding_weights)\n    \n    return train_output, infer_output",
      "execution_count": 72,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d05b663e11164cad1c637a01e8a68a8ff6822568"
      },
      "cell_type": "code",
      "source": "display_step = 150\n\nepochs = 5\nbatch_size = 8\n\nrnn_size = 64\nnum_layers = 3\n#num_layers = 1\nbeam_width = 5\n\n# as we use glove 300d\nencoding_embedding_size = 300\ndecoding_embedding_size = 300\n\nlearning_rate = 0.001\nkeep_probability = 0.5",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee470d4a05991d44f7d1caf488a77591de8defeb"
      },
      "cell_type": "code",
      "source": "save_path = 'checkpoints/dev'\n(source_int_text, target_int_text), word_to_id, id_to_word, glove_weights = load_preprocess()\nmax_target_sentence_length = max([len(sentence) for sentence in target_int_text])\n\nvocab_size = len(word_to_id)\n\ntrain_graph = tf.Graph()\nwith train_graph.as_default():\n    input_data, targets, target_sequence_length, max_target_sequence_length = enc_dec_model_inputs()\n    lr, keep_prob = hyperparam_inputs()\n    \n    train_logits, inference_output = seq2seq_model(tf.reverse(input_data, [-1]),\n                                                   targets,\n                                                   keep_prob,\n                                                   batch_size,\n                                                   target_sequence_length,\n                                                   max_target_sequence_length,\n                                                   vocab_size,\n                                                   encoding_embedding_size,\n                                                   decoding_embedding_size,\n                                                   rnn_size,\n                                                   num_layers,\n                                                   word_to_id, \n                                                   beam_width,\n                                                   glove_weights)\n    \n    \n    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n    inference_logits = tf.no_op()\n    inference_sample_id = inference_output.predicted_ids\n    \n    # https://www.tensorflow.org/api_docs/python/tf/sequence_mask\n    # - Returns a mask tensor representing the first N positions of each cell.\n    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n\n    with tf.name_scope(\"optimization\"):\n        # Loss function - weighted softmax cross entropy\n        cost = tf.contrib.seq2seq.sequence_loss(\n            training_logits,\n            targets,\n            masks)\n\n        # Optimizer\n        optimizer = tf.train.AdamOptimizer(lr)\n\n        # Gradient Clipping\n        gradients = optimizer.compute_gradients(cost)\n        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n        train_op = optimizer.apply_gradients(capped_gradients)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0730299c59fea157eaa0003c500f8ce5a93038f8"
      },
      "cell_type": "code",
      "source": "def pad_sentence_batch(sentence_batch, pad_int):\n    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n    max_sentence = max([len(sentence) for sentence in sentence_batch])\n    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n\n\ndef get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n    for batch_i in range(0, len(sources)//batch_size):\n        start_i = batch_i * batch_size\n\n        # Slice the right amount for the batch\n        sources_batch = sources[start_i:start_i + batch_size]\n        targets_batch = targets[start_i:start_i + batch_size]\n\n        # Pad\n        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n\n        # Need the lengths for the _lengths parameters\n        pad_targets_lengths = []\n        for target in pad_targets_batch:\n            pad_targets_lengths.append(len(target))\n\n        pad_source_lengths = []\n        for source in pad_sources_batch:\n            pad_source_lengths.append(len(source))\n\n        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7407b94d4dad94cb1fa759af3d7f295694a43ea5"
      },
      "cell_type": "code",
      "source": "def get_accuracy(target, logits):\n    \"\"\"\n    Calculate accuracy\n    \"\"\"\n    max_seq = max(target.shape[1], logits.shape[1])\n    if max_seq - target.shape[1]:\n        target = np.pad(\n            target,\n            [(0,0),(0,max_seq - target.shape[1])],\n            'constant')\n    if max_seq - logits.shape[1]:\n        logits = np.pad(\n            logits,\n            [(0,0),(0,max_seq - logits.shape[1])],\n            'constant')\n\n    return np.mean(np.equal(target, logits))\n\n# Split data to training and validation sets\ntrain_source = source_int_text[batch_size:]\ntrain_target = target_int_text[batch_size:]\nvalid_source = source_int_text[:batch_size]\nvalid_target = target_int_text[:batch_size]\n(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n                                                                                                             valid_target,\n                                                                                                             batch_size,\n                                                                                                             source_vocab_to_int['<PAD>'],\n                                                                                                             target_vocab_to_int['<PAD>']))                                                                                                  \nwith tf.Session(graph=train_graph) as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for epoch_i in range(epochs):\n        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n                get_batches(train_source, train_target, batch_size,\n                            source_vocab_to_int['<PAD>'],\n                            target_vocab_to_int['<PAD>'])):\n\n            _, loss = sess.run(\n                [train_op, cost],\n                {input_data: source_batch,\n                 targets: target_batch,\n                 lr: learning_rate,\n                 target_sequence_length: targets_lengths,\n                 keep_prob: keep_probability})\n            \n            if batch_i % display_step == 0 and batch_i > 0:\n                batch_train_logits = sess.run(\n                    inference_logits,\n                    {input_data: source_batch,\n                     target_sequence_length: targets_lengths,\n                     keep_prob: 1.0})\n\n                batch_valid_logits = sess.run(\n                    inference_logits,\n                    {input_data: valid_sources_batch,\n                     target_sequence_length: valid_targets_lengths,\n                     keep_prob: 1.0})\n\n                train_acc = get_accuracy(target_batch, batch_train_logits)\n                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n\n                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n\n    # Save Model\n    saver = tf.train.Saver()\n    saver.save(sess, save_path)\n    print('Model Trained and Saved')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4aef18603e20d7127c6c4a31ddb8970bdd829053"
      },
      "cell_type": "code",
      "source": "def save_params(params):\n    with open('params.p', 'wb') as out_file:\n        pickle.dump(params, out_file)\n\n\ndef load_params():\n    with open('params.p', mode='rb') as in_file:\n        return pickle.load(in_file)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "365ad1bf76e2ee58eaeb8459a1ae4a17ae077209"
      },
      "cell_type": "code",
      "source": "# Save parameters for checkpoint\nsave_params(save_path)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7791f7d6d68366f2ac3a918d24bf765b6450c75"
      },
      "cell_type": "code",
      "source": "#import problem_unittests as tests\n\n_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()\nload_path = load_params()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed6b6b724baf3da9491fcc964930247d991915d8"
      },
      "cell_type": "code",
      "source": "def sentence_to_seq(sentence, vocab_to_int):\n    results = []\n    for word in sentence.split(\" \"):\n        if word in vocab_to_int:\n            results.append(vocab_to_int[word])\n        else:\n            results.append(vocab_to_int['<UNK>'])\n            \n    return results",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "180af13c1914dc0336dbd394c03de110cddb3139"
      },
      "cell_type": "code",
      "source": "translate_sentence = ' '.join(stories[24001]['story'])\n\ntranslate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n                                \nloaded_graph = tf.Graph()\nwith tf.Session(graph=loaded_graph) as sess:\n    # Load saved model\n    loader = tf.train.import_meta_graph(load_path + '.meta')\n    loader.restore(sess, load_path)\n\n    input_data = loaded_graph.get_tensor_by_name('input:0')\n    logits = loaded_graph.get_tensor_by_name('predictions:0')\n    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n\n    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n                                         keep_prob: 1.0})[0]\nprint('Input')\n#print('  Word Ids:      {}'.format([i for i in translate_sentence]))\nprint('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n\nprint('\\nPrediction')\n#print('  Word Ids:      {}'.format([i for i in translate_logits]))\nprint('  Summary: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
